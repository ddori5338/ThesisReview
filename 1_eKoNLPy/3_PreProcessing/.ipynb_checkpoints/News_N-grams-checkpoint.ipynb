{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import pandas as pd\n",
    "import os\n",
    "from ekonlpy.sentiment import MPCK\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\student\\\\Documents\\\\Thesis\\\\1_eKoNLPy\\\\0_BOK data\\\\0_rawData\\\\news crawling\\\\csv\\\\'\n",
    "\n",
    "# 분절되어 있는 csv 파일을 읽어들여 하나의 데이터프레임으로\n",
    "total_df=pd.DataFrame({})\n",
    "for file in os.listdir(path):\n",
    "    print(file)\n",
    "    df= pd.read_csv(path + file)\n",
    "    df=df[['date','href','title','content']]\n",
    "    total_df= total_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'href'에서 매체 정보 추출\n",
    "def PressName(df):\n",
    "    if 'href' in df.columns:\n",
    "        for index in df.index:\n",
    "            if 'einfomax' in df['href'][index]:\n",
    "                df['href'][index]='연합인포맥스'\n",
    "            elif 'oid=001' in df['href'][index]:\n",
    "                df['href'][index]='연합뉴스'\n",
    "            elif 'oid=018' in df['href'][index]:\n",
    "                df['href'][index]='이데일리'\n",
    "            else:\n",
    "                df['href'][index]='unknown'\n",
    "            print('{}행의 매체명 정보를 수정 중입니다.'.format(index))\n",
    "        df.rename(columns={\"href\":\"press\"}, inplace = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(df):\n",
    "    df['tokens']=None\n",
    "    df['ngrams']=None\n",
    "\n",
    "    for index in df.index:\n",
    "        try:\n",
    "            mpck=MPCK()\n",
    "            article = df['content'][index]\n",
    "            tokens = mpck.tokenize(article)    \n",
    "            df['tokens'][index]=tokens\n",
    "\n",
    "            ngrams = mpck.ngramize(tokens)\n",
    "            df['ngrams'][index]=ngrams\n",
    "            print('{}행의 n-gramize를 완료했습니다.'.format(index))\n",
    "        except:\n",
    "            print('생략')\n",
    "            pass\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2017= pd.read_csv(path + '20170101-20171231.csv')\n",
    "df2017=get_ngrams(df2017[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017_test['ngrams'][88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
